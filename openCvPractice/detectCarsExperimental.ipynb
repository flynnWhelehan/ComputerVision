{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Load the pre-trained car detection classifier\n",
    "car_cascade = cv2.CascadeClassifier('haarCascadeCars.xml')\n",
    "\n",
    "# Open the video file\n",
    "#cap = cv2.VideoCapture('cars.mp4')\n",
    "cap = cv2.VideoCapture('MWay_traffic.wmv')\n",
    "\n",
    "# Define the colors for the boxes\n",
    "colours = [(255, 0, 0), (0, 255, 0), (0, 0, 255), (255, 255, 0), (0, 255, 255), (255, 0, 255), (128, 0, 0), \n",
    "          (0, 128, 0), (0, 0, 128), (128, 128, 0), (128, 0, 128), (255, 128, 0), \n",
    "          (255, 0, 128), (128, 255, 0), (0, 255, 128), (128, 0, 255), (0, 128, 255)]\n",
    "\n",
    "# Dictionary to keep track of cars and their IDs\n",
    "car_dict = {}\n",
    "\n",
    "# Define the threshold distance to match cars between frames\n",
    "match_threshold = 50\n",
    "\n",
    "while True:\n",
    "    # Read a frame from the video\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # If there are no more frames, break out of the loop\n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    # Convert the frame to grayscale\n",
    "    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Detect cars in the frame\n",
    "    cars = car_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=2, minSize=(20, 20))\n",
    "    \n",
    "    # Dictionary to keep track of matched cars in the current frame\n",
    "    matched_cars = {}\n",
    "    \n",
    "    # Draw bounding boxes around the detected cars\n",
    "    for i, (x, y, w, h) in enumerate(cars):\n",
    "        centroid = (x + w//2, y + h//2)\n",
    "        colour = (255, 0, 0)  # Default color\n",
    "        \n",
    "        # Match current car with the closest previous car by centroid distance\n",
    "        closest_car_id = None\n",
    "        closest_distance = np.inf\n",
    "        for car_id, car_info in car_dict.items():\n",
    "            previous_centroid = car_info['centroid']\n",
    "            distance = np.linalg.norm(np.array(centroid) - np.array(previous_centroid))\n",
    "            if distance < closest_distance:\n",
    "                closest_distance = distance\n",
    "                closest_car_id = car_id\n",
    "        \n",
    "        # If the closest previous car is within the match threshold, assume it's the same car\n",
    "        if closest_distance < match_threshold:\n",
    "            matched_cars[closest_car_id] = centroid\n",
    "            colour = car_dict[closest_car_id]['colour']\n",
    "    \n",
    "        # If not, assign a new ID and color to the car\n",
    "        else:\n",
    "            new_car_id = max(car_dict.keys()) + 1 if car_dict else 0\n",
    "            matched_cars[new_car_id] = centroid\n",
    "            colour = colours[new_car_id % len(colours)]\n",
    "        \n",
    "        # Draw the bounding box and label on the frame\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), colour, 2)\n",
    "        cv2.putText(frame, f'Car {closest_car_id}', (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, colour, 2)\n",
    "        \n",
    "            # Update the car's color in the dictionary\n",
    "    if closest_car_id in car_dict:\n",
    "        car_dict[closest_car_id]['colour'] = colour\n",
    "    \n",
    "    # If the car was not matched in the current frame, remove it from the dictionary\n",
    "    remove_keys = []\n",
    "    for car_id in car_dict.keys():\n",
    "        if car_id not in matched_cars.keys():\n",
    "            remove_keys.append(car_id)\n",
    "    for car_id in remove_keys:\n",
    "        car_dict.pop(car_id)\n",
    "        \n",
    "    # Add new cars to the dictionary\n",
    "    for car_id, centroid in matched_cars.items():\n",
    "        if car_id not in car_dict.keys():\n",
    "            car_dict[car_id] = {'centroid': centroid, 'colour': colour}\n",
    "            \n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('frame', frame)\n",
    "\n",
    "    # Exit if the user presses 'q'\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "    \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
